# # import pandas as pd
# # import numpy as np
# # from sklearn.linear_model import HuberRegressor
# # from sklearn.preprocessing import PolynomialFeatures
# # from sklearn.metrics import mean_squared_error, r2_score
# #
# # # ========= 1. è¯»å–æ•°æ® =========
# # file_path = "heat capacity 207.xlsx"
# # df = pd.read_excel(file_path, sheet_name="Sheet1")
# # df = df.dropna(subset=[df.columns[0]])  # åˆ é™¤ç¬¬ä¸€åˆ—ä¸ºç©ºçš„è¡Œ
# # df[df.columns[0]] = df[df.columns[0]].astype(int)  # å°†ç¬¬ä¸€åˆ—è½¬æ¢ä¸ºæ•´æ•°ç±»å‹
# #
# # # ========= 2. åˆ—å®šä¹‰ =========
# # group_cols = df.columns[11:30]   # 19ä¸ªåŸºå›¢åˆ—
# # temp_cols = df.columns[30:40]    # 10ä¸ªæ¸©åº¦ç‚¹
# # cp_cols = df.columns[40:50]      # 10ä¸ª Cp å€¼
# # target_column_T1 = 'ASPEN Half Critical T'
# # Tc0 = 138  # ä¸´ç•Œæ¸©åº¦å½’ä¸€åŒ–å¸¸æ•°
# #
# # # ========= 3. å­æ¨¡å‹è®­ç»ƒ =========
# # X_groups = df[group_cols]
# # valid_mask = ~df[target_column_T1].isna()
# #
# # poly = PolynomialFeatures(degree=2, include_bias=False)
# # X_poly = poly.fit_transform(X_groups[valid_mask])
# # y_exp_T1 = np.exp(df.loc[valid_mask, target_column_T1] / Tc0)
# #
# # # æ¨¡å‹æ‹Ÿåˆ
# # T1_model = HuberRegressor(max_iter=9000).fit(X_poly, y_exp_T1)
# # Cp1_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 9])
# # Cp2_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 50])
# #
# # # ========= 3.1 å­æ¨¡å‹è¯„ä¼° =========
# # y_pred_T1 = T1_model.predict(X_poly)
# # r2_T1 = r2_score(y_exp_T1, y_pred_T1)
# # mse_T1 = mean_squared_error(y_exp_T1, y_pred_T1)
# #
# # y_Cp1_true = df.iloc[:, 9]
# # y_Cp1_pred = Cp1_model.predict(X_groups)
# # r2_Cp1 = r2_score(y_Cp1_true, y_Cp1_pred)
# # mse_Cp1 = mean_squared_error(y_Cp1_true, y_Cp1_pred)
# #
# # y_Cp2_true = df.iloc[:, 50]
# # y_Cp2_pred = Cp2_model.predict(X_groups)
# # r2_Cp2 = r2_score(y_Cp2_true, y_Cp2_pred)
# # mse_Cp2 = mean_squared_error(y_Cp2_true, y_Cp2_pred)
# #
# # print("\nğŸ“Œ å­æ¨¡å‹è¯„ä¼°ç»“æœï¼š")
# # print(f"T1_model ->     RÂ²: {r2_T1:.4f} | MSE: {mse_T1:.4f}")
# # print(f"Cp1_model ->    RÂ²: {r2_Cp1:.4f} | MSE: {mse_Cp1:.4f}")
# # print(f"Cp2_model ->    RÂ²: {r2_Cp2:.4f} | MSE: {mse_Cp2:.4f}")
# #
# # # ========= 4. æ„å»ºè®­ç»ƒæ•°æ® =========
# # X_total, y_total, material_ids, temperatures = [], [], [], []
# # X_poly_all = poly.transform(X_groups)
# #
# # # å‡è®¾ extra_point_indices æ˜¯é¢å¤–ç‚¹çš„ç´¢å¼•ï¼Œä¾‹å¦‚[0, 1, 5, 7, 9]
# # extra_point_indices = [0, 1, 5, 7, 9]  # è¿™åªæ˜¯ç¤ºä¾‹ï¼Œæ ¹æ®å®é™…æ•°æ®è®¾ç½®
# #
# # # åˆ›å»ºæƒé‡æ•°ç»„ï¼Œé»˜è®¤æ¯ä¸ªç‚¹çš„æƒé‡ä¸º 1
# # weights = np.ones(len(y_total))  # é»˜è®¤æ‰€æœ‰æ ·æœ¬çš„æƒé‡ä¸º 1
# # weights[extra_point_indices] = 10  # å¯¹é¢å¤–ç‚¹èµ‹äºˆè¾ƒé«˜çš„æƒé‡ï¼Œä¾‹å¦‚æƒé‡ä¸º 10
# #
# # for i, row in df.iterrows():
# #     material_id = row.iloc[0]
# #     Nk = row[group_cols].values
# #     temps = row[temp_cols].values
# #     cps = row[cp_cols].values
# #
# #     Nk_df = pd.DataFrame([Nk], columns=group_cols)
# #     Nk_poly = X_poly_all[i:i+1]
# #
# #     try:
# #         # æ–°æ¨¡å‹ï¼šç›´æ¥é¢„æµ‹ T1ï¼ˆæ— éœ€ log å’Œ expï¼‰
# #         T1_exp = T1_model.predict(Nk_poly)[0]
# #         if T1_exp <= 0 or np.isnan(T1_exp):
# #             continue
# #         T1 = Tc0 * np.log(T1_exp)
# #         T2 = T1 * 1.5
# #         Cp1 = Cp1_model.predict(Nk_df)[0]
# #         Cp2 = Cp2_model.predict(Nk_df)[0]
# #         slope = (Cp2 - Cp1) / (T2 - T1)
# #     except:
# #         continue
# #
# #     for T, Cp in zip(temps, cps):
# #         if np.isnan(T) or np.isnan(Cp):
# #             continue
# #
# #         features = np.concatenate([
# #             Nk,           # 19 ä¸ªåŸºå›¢
# #             Nk * T,       # 19 ä¸ªäº¤äº’é¡¹
# #             [slope * T]   # slope Ã— T
# #         ])
# #
# #         X_total.append(features)
# #         y_total.append(Cp)
# #         material_ids.append(material_id)
# #         temperatures.append(T)
# #
# # # ========= 5. æ¨¡å‹æ‹Ÿåˆï¼ˆHuberï¼‰ =========
# # X_total = np.array(X_total)
# # y_total = np.array(y_total)
# #
# # # ä½¿ç”¨åŠ æƒçš„æŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒ
# # model = HuberRegressor(max_iter=10000).fit(X_total, y_total, sample_weight=weights)
# #
# # # ========= 6. æ¨¡å‹è¯„ä¼° =========
# # y_pred = model.predict(X_total)
# # mse = mean_squared_error(y_total, y_pred)
# # r2 = r2_score(y_total, y_pred)
# # ard = np.mean(np.abs((y_total - y_pred) / y_total)) * 100
# #
# # print("\nğŸ“Š æ€»æ¨¡å‹è¯„ä¼°ï¼ˆå« slopeÃ—T ç‰¹å¾ï¼‰ï¼š")
# # print(f"RÂ²  = {r2:.4f}")
# # print(f"MSE = {mse:.2f}")
# # print(f"ARD = {ard:.2f}%")
# #
# # # ========= 7. è¾“å‡ºé¢„æµ‹ç»“æœ =========
# # results = pd.DataFrame({
# #     "Material_ID": material_ids,
# #     "Temperature (K)": temperatures,
# #     "Cp_measured": y_total,
# #     "Cp_predicted": y_pred
# # })
# # results.to_excel("Cpé¢„æµ‹ç»“æœ_slopeTç‰¹å¾_Î²1å›å½’åŠ æƒ.xlsx", index=False)
# # print("âœ… å·²ä¿å­˜é¢„æµ‹ç»“æœä¸º: Cpé¢„æµ‹ç»“æœ_slopeTç‰¹å¾_Î²1å›å½’åŠ æƒ.xlsx")
# #
# # # ========= 8. è¾“å‡ºç³»æ•°è¡¨ =========
# # feature_labels = (
# #     list(group_cols) +               # 19 ä¸ªåŸºå›¢
# #     [f"{g}_T" for g in group_cols] + # 19 ä¸ªåŸºå›¢ Ã— T
# #     ["slopeÃ—T"]                      # 1 ä¸ªæ–°ç‰¹å¾
# # )
# #
# # coefficients = pd.DataFrame({
# #     "Feature": feature_labels,
# #     "Contribution": model.coef_
# # })
# # coefficients.to_excel("Cpç³»æ•°è¡¨_slopeTç‰¹å¾_Î²1å›å½’åŠ æƒ.xlsx", index=False)
# # print("ğŸ“ˆ å·²ä¿å­˜æ¨¡å‹ç³»æ•°ä¸º: Cpç³»æ•°è¡¨_slopeTç‰¹å¾_Î²1å›å½’åŠ æƒ.xlsx")
#




import pandas as pd
import numpy as np
from sklearn.linear_model import HuberRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

# ========= 1. è¯»å–æ•°æ® =========
file_path = "heat capacity 207.xlsx"
df = pd.read_excel(file_path, sheet_name="Sheet1")

# æ£€æŸ¥æ•°æ®åŠ è½½æ˜¯å¦æˆåŠŸ
print(f"Data shape: {df.shape}")
print(f"Columns: {df.columns}")

# åˆ é™¤ç¬¬ä¸€åˆ—ä¸ºç©ºçš„è¡Œ
df = df.dropna(subset=[df.columns[0]])
df[df.columns[0]] = df[df.columns[0]].astype(int)  # å°†ç¬¬ä¸€åˆ—è½¬æ¢ä¸ºæ•´æ•°ç±»å‹

# ç¡®è®¤æ•°æ®æ¸…æ´—åæ˜¯å¦æ­£ç¡®
print(f"Data shape after cleaning: {df.shape}")

# ========= 2. åˆ—å®šä¹‰ =========
group_cols = df.columns[11:30]  # 19ä¸ªåŸºå›¢åˆ—
temp_cols = df.columns[30:40]  # 10ä¸ªæ¸©åº¦ç‚¹
cp_cols = df.columns[40:50]  # 10ä¸ª Cp å€¼
target_column_T1 = 'ASPEN Half Critical T'
Tc0 = 138  # ä¸´ç•Œæ¸©åº¦å½’ä¸€åŒ–å¸¸æ•°

# ========= 3. å­æ¨¡å‹è®­ç»ƒ =========
X_groups = df[group_cols]
valid_mask = ~df[target_column_T1].isna()

poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly.fit_transform(X_groups[valid_mask])
y_exp_T1 = np.exp(df.loc[valid_mask, target_column_T1] / Tc0)

# æ¨¡å‹æ‹Ÿåˆ
T1_model = HuberRegressor(max_iter=9000).fit(X_poly, y_exp_T1)
Cp1_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 9])
Cp2_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 50])

# ========= 3.1 å­æ¨¡å‹è¯„ä¼° =========
y_pred_T1 = T1_model.predict(X_poly)
r2_T1 = r2_score(y_exp_T1, y_pred_T1)
mse_T1 = mean_squared_error(y_exp_T1, y_pred_T1)

y_Cp1_true = df.iloc[:, 9]
y_Cp1_pred = Cp1_model.predict(X_groups)
r2_Cp1 = r2_score(y_Cp1_true, y_Cp1_pred)
mse_Cp1 = mean_squared_error(y_Cp1_true, y_Cp1_pred)

y_Cp2_true = df.iloc[:, 50]
y_Cp2_pred = Cp2_model.predict(X_groups)
r2_Cp2 = r2_score(y_Cp2_true, y_Cp2_pred)
mse_Cp2 = mean_squared_error(y_Cp2_true, y_Cp2_pred)

print("\nğŸ“Œ å­æ¨¡å‹è¯„ä¼°ç»“æœï¼š")
print(f"T1_model ->     RÂ²: {r2_T1:.4f} | MSE: {mse_T1:.4f}")
print(f"Cp1_model ->    RÂ²: {r2_Cp1:.4f} | MSE: {mse_Cp1:.4f}")
print(f"Cp2_model ->    RÂ²: {r2_Cp2:.4f} | MSE: {mse_Cp2:.4f}")

# ========= 4. æ„å»ºè®­ç»ƒæ•°æ® =========
X_total, y_total, material_ids, temperatures = [], [], [], []
X_poly_all = poly.transform(X_groups)

# ç”¨äºå­˜å‚¨é¢å¤–çš„é¢„æµ‹ç‚¹ï¼ˆT1ã€Cp1ã€T2ã€Cp2ï¼‰
extra_point_weights = []  # ç”¨äºå­˜å‚¨æ¯ä¸ªæ ·æœ¬çš„é¢å¤–æƒé‡

# æ£€æŸ¥ X_total å’Œ y_total æ˜¯å¦ä¸ºç©º
print(f"Before filling: X_total size = {len(X_total)}, y_total size = {len(y_total)}")

for i, row in df.iterrows():
    material_id = row.iloc[0]
    Nk = row[group_cols].values
    temps = row[temp_cols].values
    cps = row[cp_cols].values

    Nk_df = pd.DataFrame([Nk], columns=group_cols)
    Nk_poly = X_poly_all[i:i + 1]

    try:
        # æ–°æ¨¡å‹ï¼šç›´æ¥é¢„æµ‹ T1ï¼ˆæ— éœ€ log å’Œ expï¼‰
        T1_exp = T1_model.predict(Nk_poly)[0]
        if T1_exp <= 0 or np.isnan(T1_exp):
            continue
        T1 = Tc0 * np.log(T1_exp)
        T2 = T1 * 1.5
        Cp1 = Cp1_model.predict(Nk_df)[0]
        Cp2 = Cp2_model.predict(Nk_df)[0]
        slope = (Cp2 - Cp1) / (T2 - T1)

        # ä¸ºé¢„æµ‹çš„ T1ã€Cp1ã€T2ã€Cp2 ç”Ÿæˆæƒé‡ï¼ˆç”¨äºåŠ æƒæŸå¤±ï¼‰
        extra_point_weights.append(2.2)  # å¯ä»¥è°ƒæ•´æƒé‡å€¼ï¼ˆå¦‚ 10ï¼‰ä»¥å¼ºè°ƒè¿™äº›é¢„æµ‹ç‚¹
    except:
        continue

    for T, Cp in zip(temps, cps):
        if np.isnan(T) or np.isnan(Cp):
            continue

        features = np.concatenate([
            Nk,  # 19 ä¸ªåŸºå›¢
            Nk * T,  # 19 ä¸ªäº¤äº’é¡¹
            [slope * T]  # slope Ã— T
        ])

        X_total.append(features)
        y_total.append(Cp)
        material_ids.append(material_id)
        temperatures.append(T)

# æ£€æŸ¥ X_total å’Œ y_total å¡«å……åçš„å¤§å°
print(f"After filling: X_total size = {len(X_total)}, y_total size = {len(y_total)}")

# ç¡®ä¿ X_total å’Œ y_total ä¸ä¸ºç©ºï¼Œç»§ç»­è®­ç»ƒ
if len(X_total) > 0 and len(y_total) > 0:
    # é‡æ–°å®šä¹‰æƒé‡
    weights = np.ones(len(y_total))  # é»˜è®¤æ‰€æœ‰æ ·æœ¬çš„æƒé‡ä¸º 1

    # ç»™é¢å¤–çš„é¢„æµ‹ç‚¹ï¼ˆT1ã€Cp1ã€T2ã€Cp2ï¼‰å¢åŠ æ›´é«˜çš„æƒé‡
    weights[-len(extra_point_weights):] = extra_point_weights  # å°†é¢„æµ‹ç‚¹çš„æƒé‡è®¾ç½®ä¸º 10

    # ä½¿ç”¨åŠ æƒçš„æŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒ
    model = HuberRegressor(max_iter=20000).fit(X_total, y_total, sample_weight=weights)

    # ========= 6. æ¨¡å‹è¯„ä¼° =========
    y_pred = model.predict(X_total)
    mse = mean_squared_error(y_total, y_pred)
    r2 = r2_score(y_total, y_pred)
    ard = np.mean(np.abs((y_total - y_pred) / y_total)) * 100

    print("\nğŸ“Š æ€»æ¨¡å‹è¯„ä¼°ï¼ˆå« slopeÃ—T ç‰¹å¾ï¼‰ï¼š")
    print(f"RÂ²  = {r2:.4f}")
    print(f"MSE = {mse:.2f}")
    print(f"ARD = {ard:.2f}%")

    # ========= 7. è¾“å‡ºé¢„æµ‹ç»“æœ =========
    results = pd.DataFrame({
        "Material_ID": material_ids,
        "Temperature (K)": temperatures,
        "Cp_measured": y_total,
        "Cp_predicted": y_pred
    })
    results.to_excel("Cpé¢„æµ‹ç»“æœ_slopeTç‰¹å¾_Î²1å›å½’åŠ æƒ.xlsx", index=False)
    print("âœ… å·²ä¿å­˜é¢„æµ‹ç»“æœä¸º: Cpé¢„æµ‹ç»“æœ_slopeTç‰¹å¾_Î²1å›å½’åŠ æƒ.xlsx")

    # ========= 8. è¾“å‡ºç³»æ•°è¡¨ =========
    feature_labels = (
            list(group_cols) +  # 19 ä¸ªåŸºå›¢
            [f"{g}_T" for g in group_cols] +  # 19 ä¸ªåŸºå›¢ Ã— T
            ["slopeÃ—T"]  # 1 ä¸ªæ–°ç‰¹å¾
    )

    coefficients = pd.DataFrame({
        "Feature": feature_labels,
        "Contribution": model.coef_
    })
    coefficients.to_excel("Cpç³»æ•°è¡¨_slopeTç‰¹å¾_Î²1å›å½’åŠ æƒ.xlsx", index=False)
    print("ğŸ“ˆ å·²ä¿å­˜æ¨¡å‹ç³»æ•°ä¸º: Cpç³»æ•°è¡¨_slopeTç‰¹å¾_Î²1å›å½’åŠ æƒ.xlsx")
else:
    print("é”™è¯¯ï¼šè®­ç»ƒæ•°æ®ä¸ºç©ºï¼")
# import pandas as pd
# import numpy as np
# from sklearn.linear_model import HuberRegressor
# from sklearn.preprocessing import PolynomialFeatures
# from sklearn.metrics import mean_squared_error, r2_score
# import matplotlib.pyplot as plt
#
# # ========= 1. è¯»å–æ•°æ® =========
# file_path = "heat capacity 207.xlsx"
# df = pd.read_excel(file_path, sheet_name="Sheet1")
#
# # æ£€æŸ¥æ•°æ®åŠ è½½æ˜¯å¦æˆåŠŸ
# print(f"Data shape: {df.shape}")
# print(f"Columns: {df.columns}")
#
# # åˆ é™¤ç¬¬ä¸€åˆ—ä¸ºç©ºçš„è¡Œ
# df = df.dropna(subset=[df.columns[0]])
# df[df.columns[0]] = df[df.columns[0]].astype(int)  # å°†ç¬¬ä¸€åˆ—è½¬æ¢ä¸ºæ•´æ•°ç±»å‹
#
# # ç¡®è®¤æ•°æ®æ¸…æ´—åæ˜¯å¦æ­£ç¡®
# print(f"Data shape after cleaning: {df.shape}")
#
# # ========= 2. åˆ—å®šä¹‰ =========
# group_cols = df.columns[11:30]  # 19ä¸ªåŸºå›¢åˆ—
# temp_cols = df.columns[30:40]  # 10ä¸ªæ¸©åº¦ç‚¹
# cp_cols = df.columns[40:50]  # 10ä¸ª Cp å€¼
# target_column_T1 = 'ASPEN Half Critical T'
# Tc0 = 138  # ä¸´ç•Œæ¸©åº¦å½’ä¸€åŒ–å¸¸æ•°
#
# # ========= 3. å­æ¨¡å‹è®­ç»ƒ =========
# X_groups = df[group_cols]
# valid_mask = ~df[target_column_T1].isna()
#
# poly = PolynomialFeatures(degree=2, include_bias=False)
# X_poly = poly.fit_transform(X_groups[valid_mask])
# y_exp_T1 = np.exp(df.loc[valid_mask, target_column_T1] / Tc0)
#
# # æ¨¡å‹æ‹Ÿåˆ
# T1_model = HuberRegressor(max_iter=9000).fit(X_poly, y_exp_T1)
# Cp1_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 9])
# Cp2_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 50])
#
# # ========= 3.1 å­æ¨¡å‹è¯„ä¼° =========
# y_pred_T1 = T1_model.predict(X_poly)
# r2_T1 = r2_score(y_exp_T1, y_pred_T1)
# mse_T1 = mean_squared_error(y_exp_T1, y_pred_T1)
#
# y_Cp1_true = df.iloc[:, 9]
# y_Cp1_pred = Cp1_model.predict(X_groups)
# r2_Cp1 = r2_score(y_Cp1_true, y_Cp1_pred)
# mse_Cp1 = mean_squared_error(y_Cp1_true, y_Cp1_pred)
#
# y_Cp2_true = df.iloc[:, 50]
# y_Cp2_pred = Cp2_model.predict(X_groups)
# r2_Cp2 = r2_score(y_Cp2_true, y_Cp2_pred)
# mse_Cp2 = mean_squared_error(y_Cp2_true, y_Cp2_pred)
#
# print("\nğŸ“Œ å­æ¨¡å‹è¯„ä¼°ç»“æœï¼š")
# print(f"T1_model ->     RÂ²: {r2_T1:.4f} | MSE: {mse_T1:.4f}")
# print(f"Cp1_model ->    RÂ²: {r2_Cp1:.4f} | MSE: {mse_Cp1:.4f}")
# print(f"Cp2_model ->    RÂ²: {r2_Cp2:.4f} | MSE: {mse_Cp2:.4f}")
#
# # ========= 4. æ„å»ºè®­ç»ƒæ•°æ® =========
# X_total, y_total, material_ids, temperatures = [], [], [], []
# X_poly_all = poly.transform(X_groups)
#
# # å­˜å‚¨é¢å¤–ç‚¹çš„ç´¢å¼•ï¼ˆT1ã€Cp1ã€T2ã€Cp2å¯¹åº”çš„ç‚¹ï¼‰
# extra_point_indices = []
#
# for i, row in df.iterrows():
#     material_id = row.iloc[0]
#     Nk = row[group_cols].values
#     temps = row[temp_cols].values
#     cps = row[cp_cols].values
#
#     Nk_df = pd.DataFrame([Nk], columns=group_cols)
#     Nk_poly = X_poly_all[i:i + 1]
#
#     try:
#         # æ–°æ¨¡å‹ï¼šç›´æ¥é¢„æµ‹ T1ï¼ˆæ— éœ€ log å’Œ expï¼‰
#         T1_exp = T1_model.predict(Nk_poly)[0]
#         if T1_exp <= 0 or np.isnan(T1_exp):
#             continue
#         T1 = Tc0 * np.log(T1_exp)
#         T2 = T1 * 1.5
#         Cp1 = Cp1_model.predict(Nk_df)[0]
#         Cp2 = Cp2_model.predict(Nk_df)[0]
#         slope = (Cp2 - Cp1) / (T2 - T1)
#
#         # å°† T1, Cp1, T2, Cp2 å¯¹åº”çš„ç‚¹ä½œä¸ºé¢å¤–ç‚¹
#         extra_point_indices.append(len(X_total))  # å°†å½“å‰ç´¢å¼•ä½œä¸ºé¢å¤–ç‚¹çš„ç´¢å¼•
#
#     except:
#         continue
#
#     for T, Cp in zip(temps, cps):
#         if np.isnan(T) or np.isnan(Cp):
#             continue
#
#         features = np.concatenate([
#             Nk,  # 19 ä¸ªåŸºå›¢
#             Nk * T,  # 19 ä¸ªäº¤äº’é¡¹
#             [slope * T]  # slope Ã— T
#         ])
#
#         X_total.append(features)
#         y_total.append(Cp)
#         material_ids.append(material_id)
#         temperatures.append(T)
#
# # è½¬æ¢ä¸ºnumpyæ•°ç»„
# X_total = np.array(X_total)
# y_total = np.array(y_total)
#
# print(f"After filling: X_total size = {len(X_total)}, y_total size = {len(y_total)}")
# print(f"Extra point indices: {len(extra_point_indices)}")
#
#
# # ========= 5. æƒé‡è‡ªåŠ¨ä¼˜åŒ– =========
# def evaluate_model_with_weight(weight_value, X_train, y_train, extra_indices):
#     """ä½¿ç”¨ç»™å®šæƒé‡è¯„ä¼°æ¨¡å‹"""
#     weights = np.ones(len(y_train))
#     if len(extra_indices) > 0:
#         # åªè°ƒæ•´è®­ç»ƒé›†ä¸­å­˜åœ¨çš„é¢å¤–ç‚¹ç´¢å¼•
#         train_extra_indices = [i for i in extra_indices if i < len(weights)]
#         weights[train_extra_indices] = weight_value
#
#     model = HuberRegressor(max_iter=100000000000).fit(X_train, y_train, sample_weight=weights)
#     y_pred = model.predict(X_train)
#     mse = mean_squared_error(y_train, y_pred)
#     r2 = r2_score(y_train, y_pred)
#     return mse, r2, model
#
#
# # æµ‹è¯•ä¸åŒçš„æƒé‡å€¼ï¼ˆ0-20ï¼Œé—´éš”0.2ï¼‰
# weight_values = np.arange(0, 20, 0.2)
# best_mse = np.inf
# best_r2 = -np.inf
# best_weight = 1.0
# best_model = None
# results = []
#
# print("\nğŸ” å¼€å§‹æƒé‡è‡ªåŠ¨ä¼˜åŒ–ï¼ˆMSEæœ€å°åŒ–ï¼‰...")
# print("æƒé‡å€¼\tMSE\t\tRÂ²")
#
# for weight in weight_values:
#     mse, r2, model = evaluate_model_with_weight(weight, X_total, y_total, extra_point_indices)
#     results.append((weight, mse, r2))
#
#     if weight % 2 == 0:  # æ¯2.0æ‰“å°ä¸€æ¬¡è¿›åº¦
#         print(f"{weight:.1f}\t{mse:.6f}\t{r2:.4f}")
#
#     if mse < best_mse:
#         best_mse = mse
#         best_r2 = r2
#         best_weight = weight
#         best_model = model
#
# print(f"\nğŸ¯ æœ€ä½³æƒé‡: {best_weight:.1f}")
# print(f"æœ€ä½³ MSE: {best_mse:.6f}")
# print(f"æœ€ä½³ RÂ²: {best_r2:.4f}")
#
# # ========= 6. ä½¿ç”¨æœ€ä½³æƒé‡è®­ç»ƒæœ€ç»ˆæ¨¡å‹ =========
# print(f"\nğŸš€ ä½¿ç”¨æœ€ä½³æƒé‡ {best_weight:.1f} è®­ç»ƒæœ€ç»ˆæ¨¡å‹...")
#
# # ä½¿ç”¨æœ€ä½³æƒé‡è®­ç»ƒæœ€ç»ˆæ¨¡å‹ï¼Œä½¿ç”¨æ‰€æœ‰æ•°æ®
# final_weights = np.ones(len(y_total))
# if len(extra_point_indices) > 0:
#     final_weights[extra_point_indices] = best_weight
#
# final_model = HuberRegressor(max_iter=1000000000000).fit(X_total, y_total, sample_weight=final_weights)
#
# # ========= 7. æœ€ç»ˆæ¨¡å‹è¯„ä¼° =========
# y_pred = final_model.predict(X_total)
# mse = mean_squared_error(y_total, y_pred)
# r2 = r2_score(y_total, y_pred)
# ard = np.mean(np.abs((y_total - y_pred) / np.clip(np.abs(y_total), 1e-10, None))) * 100
#
# print("\nğŸ“Š æœ€ç»ˆæ¨¡å‹è¯„ä¼°ç»“æœï¼š")
# print(f"æœ€ä½³æƒé‡: {best_weight:.1f}")
# print(f"RÂ²  = {r2:.4f}")
# print(f"MSE = {mse:.4f}")
# print(f"ARD = {ard:.2f}%")
#
# # ========= 8. ç»˜åˆ¶æƒé‡ä¼˜åŒ–ç»“æœ =========
# weights, mses, r2s = zip(*results)
#
# plt.figure(figsize=(12, 5))
#
# plt.subplot(1, 2, 1)
# plt.plot(weights, mses, 'ro-', linewidth=2, markersize=4)
# plt.axvline(x=best_weight, color='blue', linestyle='--', label=f'æœ€ä½³æƒé‡: {best_weight:.1f}')
# plt.xlabel('æƒé‡å€¼')
# plt.ylabel('MSE')
# plt.title('æƒé‡ä¼˜åŒ– - MSE vs æƒé‡å€¼')
# plt.legend()
# plt.grid(True, alpha=0.3)
#
# plt.subplot(1, 2, 2)
# plt.plot(weights, r2s, 'go-', linewidth=2, markersize=4)
# plt.axvline(x=best_weight, color='blue', linestyle='--', label=f'æœ€ä½³æƒé‡: {best_weight:.1f}')
# plt.xlabel('æƒé‡å€¼')
# plt.ylabel('RÂ²')
# plt.title('æƒé‡ä¼˜åŒ– - RÂ² vs æƒé‡å€¼')
# plt.legend()
# plt.grid(True, alpha=0.3)
#
# plt.tight_layout()
# plt.savefig('æƒé‡ä¼˜åŒ–ç»“æœ_MSEæœ€å°åŒ–.png', dpi=300, bbox_inches='tight')
# plt.show()
