# import pandas as pd
# import numpy as np
# from sklearn.linear_model import HuberRegressor
# from sklearn.ensemble import GradientBoostingRegressor
# from sklearn.preprocessing import PolynomialFeatures
# from sklearn.metrics import mean_squared_error, r2_score
#
# # ========= 1. è¯»å–æ•°æ® =========
# file_path = "heat capacity 207.xlsx"
# df = pd.read_excel(file_path, sheet_name="Sheet1")
# df = df.dropna(subset=[df.columns[0]])
# df[df.columns[0]] = df[df.columns[0]].astype(int)
#
# # ========= 2. åˆ—å®šä¹‰ =========
# group_cols = df.columns[11:30]  # 19ä¸ªåŸºå›¢åˆ—
# temp_cols = df.columns[30:40]  # 10ä¸ªæ¸©åº¦ç‚¹
# cp_cols = df.columns[40:50]  # 10ä¸ª Cp å€¼
# target_column_T1 = 'ASPEN Half Critical T'
#
# # ========= 3. å­æ¨¡å‹è®­ç»ƒ =========
# X_groups = df[group_cols]
# valid_mask = ~df[target_column_T1].isna()
#
# poly = PolynomialFeatures(degree=2, include_bias=False)
# X_poly = poly.fit_transform(X_groups[valid_mask])
#
# # æ”¹ç”¨ GradientBoostingRegressor é¢„æµ‹ T1
# y_T1 = df.loc[valid_mask, target_column_T1].values
# T1_model = GradientBoostingRegressor(
#     n_estimators=300, learning_rate=0.05, max_depth=4, random_state=0
# ).fit(X_poly, y_T1)
#
# # Cp1, Cp2 ä½¿ç”¨ HuberRegressor
# Cp1_model = HuberRegressor(max_iter=9000000000).fit(X_groups, df.iloc[:, 9])
# Cp2_model = HuberRegressor(max_iter=9000000000).fit(X_groups, df.iloc[:, 50])
#
# # ========= 3.1 å­æ¨¡å‹è¯„ä¼° =========
# y_pred_T1 = T1_model.predict(X_poly)
# r2_T1 = r2_score(y_T1, y_pred_T1)
# mse_T1 = mean_squared_error(y_T1, y_pred_T1)
#
# y_Cp1_true = df.iloc[:, 9]
# y_Cp1_pred = Cp1_model.predict(X_groups)
# r2_Cp1 = r2_score(y_Cp1_true, y_Cp1_pred)
# mse_Cp1 = mean_squared_error(y_Cp1_true, y_Cp1_pred)
#
# y_Cp2_true = df.iloc[:, 50]
# y_Cp2_pred = Cp2_model.predict(X_groups)
# r2_Cp2 = r2_score(y_Cp2_true, y_Cp2_pred)
# mse_Cp2 = mean_squared_error(y_Cp2_true, y_Cp2_pred)
#
# print("\nğŸ“Œ å­æ¨¡å‹è¯„ä¼°ç»“æœï¼š")
# print(f"T1_model ->     RÂ²: {r2_T1:.4f} | MSE: {mse_T1:.4f}")
# print(f"Cp1_model ->    RÂ²: {r2_Cp1:.4f} | MSE: {mse_Cp1:.4f}")
# print(f"Cp2_model ->    RÂ²: {r2_Cp2:.4f} | MSE: {mse_Cp2:.4f}")
#
# # ========= 4. æ„å»ºè®­ç»ƒæ•°æ® =========
# X_total, y_total, material_ids, temperatures = [], [], [], []
# X_poly_all = poly.transform(X_groups)
#
# for i, row in df.iterrows():
#     material_id = row.iloc[0]
#     Nk = row[group_cols].values
#     temps = row[temp_cols].values
#     cps = row[cp_cols].values
#
#     Nk_df = pd.DataFrame([Nk], columns=group_cols)
#     Nk_poly = X_poly_all[i:i + 1]
#
#     try:
#         # ç›´æ¥é¢„æµ‹ T1ï¼ˆæ— éœ€ log å’Œ expï¼‰
#         T1 = T1_model.predict(Nk_poly)[0]
#         if T1 <= 0 or np.isnan(T1):
#             continue
#         T2 = T1 * 1.5
#         Cp1 = Cp1_model.predict(Nk_df)[0]
#         Cp2 = Cp2_model.predict(Nk_df)[0]
#         slope = (Cp2 - Cp1) / (T2 - T1)
#
#         # è®¡ç®—Cp1å’ŒCp2çš„æ®‹å·®
#         Cp1_residual = cps[0] - Cp1  # å‡è®¾ç¬¬ä¸€åˆ—cpæ˜¯å®é™…å€¼
#         Cp2_residual = cps[1] - Cp2  # å‡è®¾ç¬¬äºŒåˆ—cpæ˜¯å®é™…å€¼
#
#     except:
#         continue
#
#     for T, Cp in zip(temps, cps):
#         if np.isnan(T) or np.isnan(Cp):
#             continue
#
#         # å°†æ®‹å·®ä½œä¸ºé¢å¤–ç‰¹å¾åŠ å…¥åˆ°æ¨¡å‹ç‰¹å¾ä¸­
#         features = np.concatenate([
#             Nk,  # 19 ä¸ªåŸºå›¢
#             Nk * T,  # 19 ä¸ªäº¤äº’é¡¹
#             [slope * T],  # slope Ã— T
#             [Cp1_residual],  # Cp1çš„æ®‹å·®
#             [Cp2_residual]  # Cp2çš„æ®‹å·®
#         ])
#
#         X_total.append(features)
#         y_total.append(Cp)
#         material_ids.append(material_id)
#         temperatures.append(T)
#
# # ========= 5. æ¨¡å‹æ‹Ÿåˆï¼ˆHuberï¼‰ =========
# X_total = np.array(X_total)
# y_total = np.array(y_total)
#
# model = HuberRegressor(max_iter=200000000000).fit(X_total, y_total)
#
# # ========= 6. æ¨¡å‹è¯„ä¼° =========
# y_pred = model.predict(X_total)
# mse = mean_squared_error(y_total, y_pred)
# r2 = r2_score(y_total, y_pred)
# ard = np.mean(np.abs((y_total - y_pred) / y_total)) * 100
#
# print("\nğŸ“Š æ€»æ¨¡å‹è¯„ä¼°ï¼ˆå« slopeÃ—T ç‰¹å¾ï¼‰ï¼š")
# print(f"RÂ²  = {r2:.4f}")
# print(f"MSE = {mse:.2f}")
# print(f"ARD = {ard:.2f}%")
#
# # ========= 7. è¾“å‡ºé¢„æµ‹ç»“æœ =========
# results = pd.DataFrame({
#     "Material_ID": material_ids,
#     "Temperature (K)": temperatures,
#     "Cp_measured": y_total,
#     "Cp_predicted": y_pred
# })
# results.to_excel("Cpé¢„æµ‹ç»“æœ_æ®‹å·®ç‰¹å¾_Î²1å›å½’.xlsx", index=False)
# print("âœ… å·²ä¿å­˜é¢„æµ‹ç»“æœä¸º: Cpé¢„æµ‹ç»“æœ_æ®‹å·®ç‰¹å¾_Î²1å›å½’.xlsx")
#
# # ========= 8. è¾“å‡ºç³»æ•°è¡¨ =========
# feature_labels = (
#     list(group_cols) +               # 19 ä¸ªåŸºå›¢
#     [f"{g}_T" for g in group_cols] + # 19 ä¸ªåŸºå›¢ Ã— T
#     ["slopeÃ—T"]                      # 1 ä¸ªæ–°ç‰¹å¾
# )
#
# # æ·»åŠ æ®‹å·®ç‰¹å¾
# feature_labels += ['Cp1_residual', 'Cp2_residual']
#
# # è·å–æ¨¡å‹çš„ç³»æ•°
# coefficients = pd.DataFrame({
#     "Feature": feature_labels,
#     "Coefficient": model.coef_
# })
#
# # ä¿å­˜ç³»æ•°è¡¨
# coefficients.to_excel("Cpç³»æ•°è¡¨_æ®‹å·®ç‰¹å¾_Î²1å›å½’.xlsx", index=False)
# print("ğŸ“ˆ å·²ä¿å­˜æ¨¡å‹ç³»æ•°ä¸º: Cpç³»æ•°è¡¨_æ®‹å·®ç‰¹å¾_Î²1å›å½’.xlsx")


import pandas as pd
import numpy as np
from sklearn.linear_model import HuberRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.metrics import mean_squared_error, r2_score

# 1. è¯»å–æ•°æ®
file_path = "heat capacity 207.xlsx"
df = pd.read_excel(file_path, sheet_name="Sheet1")
df = df.dropna(subset=[df.columns[0]])  # å»é™¤ç©ºå€¼è¡Œ
df[df.columns[0]] = df[df.columns[0]].astype(int)  # å°†ç¬¬ä¸€åˆ—è½¬æ¢ä¸ºæ•´æ•°ç±»å‹

# 2. åˆ—å®šä¹‰
group_cols = df.columns[11:30]   # 12ä¸ªåŸºå›¢åˆ—
temp_cols = df.columns[30:40]    # 10ä¸ªæ¸©åº¦ç‚¹
cp_cols = df.columns[40:50]      # 10ä¸ª Cp å€¼
target_column_T1 = 'ASPEN Half Critical T'
Tc0 = 138

# 3. å­æ¨¡å‹è®­ç»ƒï¼šç”¨äºä¼°ç®— T1, Cp1, Cp2 â†’ è®¡ç®— slope
X_groups = df[group_cols]
valid_mask = ~df[target_column_T1].isna()
poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly.fit_transform(X_groups[valid_mask])
y_exp_T1 = np.exp(df.loc[valid_mask, target_column_T1] / Tc0)

T1_model = HuberRegressor(max_iter=9000).fit(X_poly, y_exp_T1)
Cp1_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 9])
Cp2_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 50])

# 4. æ„å»ºè®­ç»ƒæ•°æ®
X_total, y_total, material_ids, temperatures = [], [], [], []
X_poly_all = poly.transform(X_groups)

for i, row in df.iterrows():
    material_id = row.iloc[0]
    Nk = row[group_cols].values
    temps = row[temp_cols].values
    cps = row[cp_cols].values

    Nk_df = pd.DataFrame([Nk], columns=group_cols)
    Nk_poly = X_poly_all[i:i + 1]

    try:
        # ç›´æ¥é¢„æµ‹ T1ï¼ˆæ— éœ€ log å’Œ expï¼‰
        T1_exp = T1_model.predict(Nk_poly)[0]
        if T1_exp <= 0 or np.isnan(T1_exp):
            continue
        T1 = Tc0 * np.log(T1_exp)
        T2 = T1 * 1.5
        Cp1 = Cp1_model.predict(Nk_df)[0]
        Cp2 = Cp2_model.predict(Nk_df)[0]
        slope = (Cp2 - Cp1) / (T2 - T1)

        # è·å– Cp1 å’Œ Cp2 çš„å®é™…å€¼
        Cp1_true = df.iloc[i, 9]  # å®é™…çš„ Cp1
        Cp2_true = df.iloc[i, 50]  # å®é™…çš„ Cp2

        # è®¡ç®—æ®‹å·®
        Cp1_residual = Cp1_true - Cp1  # å®é™…å€¼ - é¢„æµ‹å€¼
        Cp2_residual = Cp2_true - Cp2  # å®é™…å€¼ - é¢„æµ‹å€¼

    except:
        continue

    for T, Cp in zip(temps, cps):
        if np.isnan(T) or np.isnan(Cp):
            continue

        # å°†æ®‹å·®ä½œä¸ºé¢å¤–ç‰¹å¾åŠ å…¥åˆ°æ¨¡å‹ç‰¹å¾ä¸­
        features = np.concatenate([
            Nk,            # 12 ä¸ªåŸºå›¢
            Nk * T,        # 12 ä¸ªåŸºå›¢ Ã— æ¸©åº¦
            [slope * T],   # slope Ã— T
            [Cp1_residual], # Cp1çš„æ®‹å·®
            [Cp2_residual]  # Cp2çš„æ®‹å·®
        ])

        X_total.append(features)
        y_total.append(Cp)
        material_ids.append(material_id)
        temperatures.append(T)

# ========= 5. æ•°æ®æ ‡å‡†åŒ– =========
scaler = StandardScaler()
X_total_scaled = scaler.fit_transform(X_total)

# ========= 6. æ¨¡å‹æ‹Ÿåˆï¼ˆHuberï¼‰ =========
model = HuberRegressor(max_iter=20000).fit(X_total_scaled, y_total)

# ========= 7. æ¨¡å‹è¯„ä¼° =========
y_pred = model.predict(X_total_scaled)
mse = mean_squared_error(y_total, y_pred)
r2 = r2_score(y_total, y_pred)
ard = np.mean(np.abs((y_total - y_pred) / y_total)) * 100

print("\nğŸ“Š æ€»æ¨¡å‹è¯„ä¼°ï¼ˆå« slopeÃ—T ç‰¹å¾ï¼‰ï¼š")
print(f"RÂ²  = {r2:.4f}")
print(f"MSE = {mse:.2f}")
print(f"ARD = {ard:.2f}%")

# ========= 8. è¾“å‡ºé¢„æµ‹ç»“æœ =========
results = pd.DataFrame({
    "Material_ID": material_ids,
    "Temperature (K)": temperatures,
    "Cp_measured": y_total,
    "Cp_predicted": y_pred
})
results.to_excel("Cpé¢„æµ‹ç»“æœ_æ®‹å·®ç‰¹å¾_Î²1å›å½’.xlsx", index=False)
print("âœ… å·²ä¿å­˜é¢„æµ‹ç»“æœä¸º: Cpé¢„æµ‹ç»“æœ_æ®‹å·®ç‰¹å¾_Î²1å›å½’.xlsx")

# ========= 9. è¾“å‡ºç³»æ•°è¡¨ =========
feature_labels = (
        list(group_cols) +               # 19 ä¸ªåŸºå›¢
        [f"{g}_T" for g in group_cols] + # 12 ä¸ªåŸºå›¢ Ã— æ¸©åº¦
        ["slopeÃ—T", "Cp1_residual", "Cp2_residual"]  # æ–°å¢ç‰¹å¾
)

coefficients = pd.DataFrame({
    "Feature": feature_labels,
    "Contribution": model.coef_
})
coefficients.to_excel("Cpç³»æ•°è¡¨_æ®‹å·®ç‰¹å¾_Î²1å›å½’.xlsx", index=False)
print("ğŸ“ˆ å·²ä¿å­˜æ¨¡å‹ç³»æ•°ä¸º: Cpç³»æ•°è¡¨_æ®‹å·®ç‰¹å¾_Î²1å›å½’.xlsx")
