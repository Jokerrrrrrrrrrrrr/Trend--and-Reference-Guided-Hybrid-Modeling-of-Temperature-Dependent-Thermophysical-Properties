import pandas as pd
import numpy as np
from sklearn.linear_model import HuberRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

# 1. è¯»å–æ•°æ®
file_path = "heat capacity 207.xlsx"
df = pd.read_excel(file_path, sheet_name="Sheet1")
df = df.dropna(subset=[df.columns[0]])
df[df.columns[0]] = df[df.columns[0]].astype(int)

# 2. åˆ—å®šä¹‰
group_cols = df.columns[11:30]   # åŸºå›¢åˆ—
temp_cols  = df.columns[30:40]   # 10ä¸ªæ¸©åº¦ç‚¹
cp_cols    = df.columns[40:50]   # 10ä¸ª Cp å€¼
target_column_T1 = 'ASPEN Half Critical T'
Tc0 = 138

# çœŸå®å››åˆ—ï¼šCp1_true=ç¬¬10åˆ—, Cp2_true=ç¬¬51åˆ—, T1_true=target_column_T1, T2_true=1.5*T1_true
CP1_TRUE_IDX = 9
CP2_TRUE_IDX = 50
T1_TRUE_COL  = target_column_T1

# 2.1 å¼ºåˆ¶æ•°å€¼åŒ–ï¼ˆé¿å… isnan åœ¨ object ä¸ŠæŠ¥é”™ï¼‰
df[group_cols] = df[group_cols].apply(pd.to_numeric, errors="coerce")
df[temp_cols]  = df[temp_cols].apply(pd.to_numeric, errors="coerce")
df[cp_cols]    = df[cp_cols].apply(pd.to_numeric, errors="coerce")
df.iloc[:, CP1_TRUE_IDX] = pd.to_numeric(df.iloc[:, CP1_TRUE_IDX], errors="coerce")
df.iloc[:, CP2_TRUE_IDX] = pd.to_numeric(df.iloc[:, CP2_TRUE_IDX], errors="coerce")
df[T1_TRUE_COL]          = pd.to_numeric(df[T1_TRUE_COL], errors="coerce")

# 3. å­æ¨¡å‹è®­ç»ƒï¼šç”¨äºä¼°ç®— T1, Cp1, Cp2 â†’ è®¡ç®— slope
X_groups = df[group_cols]
valid_mask = X_groups.notna().all(1) & df[target_column_T1].notna()
poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly.fit_transform(X_groups[valid_mask])
y_exp_T1 = np.exp(df.loc[valid_mask, target_column_T1] / Tc0)

T1_model  = HuberRegressor(max_iter=9000).fit(X_poly, y_exp_T1)
Cp1_model = HuberRegressor(max_iter=9000).fit(X_groups.fillna(0), df.iloc[:, CP1_TRUE_IDX].fillna(0))
Cp2_model = HuberRegressor(max_iter=9000).fit(X_groups.fillna(0), df.iloc[:, CP2_TRUE_IDX].fillna(0))

# 3.1 å­æ¨¡å‹ï¼ˆin-sampleï¼‰è¯„ä¼°
y_pred_T1_exp = T1_model.predict(X_poly)
print("\nğŸ“Œ å­æ¨¡å‹è¯„ä¼°ç»“æœï¼š")
print(f"T1_model ->     RÂ²: {r2_score(y_exp_T1, y_pred_T1_exp):.4f} | MSE: {mean_squared_error(y_exp_T1, y_pred_T1_exp):.4f}")

mask_cp_eval = X_groups.notna().all(1) & df.iloc[:, CP1_TRUE_IDX].notna()
y_Cp1_true = df.iloc[:, CP1_TRUE_IDX][mask_cp_eval]
y_Cp1_pred = Cp1_model.predict(X_groups[mask_cp_eval].fillna(0))
print(f"Cp1_model ->    RÂ²: {r2_score(y_Cp1_true, y_Cp1_pred):.4f} | MSE: {mean_squared_error(y_Cp1_true, y_Cp1_pred):.4f}")

mask_cp2_eval = X_groups.notna().all(1) & df.iloc[:, CP2_TRUE_IDX].notna()
y_Cp2_true = df.iloc[:, CP2_TRUE_IDX][mask_cp2_eval]
y_Cp2_pred = Cp2_model.predict(X_groups[mask_cp2_eval].fillna(0))
print(f"Cp2_model ->    RÂ²: {r2_score(y_Cp2_true, y_Cp2_pred):.4f} | MSE: {mean_squared_error(y_Cp2_true, y_Cp2_pred):.4f}")

# 4. æ„å»ºè®­ç»ƒæ•°æ® â€”â€” å››ç§ slope å˜ä½“
variants = {
    "A_çœŸå®Î”Cp_é¢„æµ‹Î”T": ("realCp", "predT"),
    "B_é¢„æµ‹Î”Cp_çœŸå®Î”T": ("predCp", "realT"),
    "C_é¢„æµ‹Î”Cp_é¢„æµ‹Î”T": ("predCp", "predT"),
    "D_çœŸå®Î”Cp_çœŸå®Î”T": ("realCp", "realT"),
}
datasets = {k: {"X": [], "y": [], "id": [], "T": []} for k in variants.keys()}

X_poly_all = poly.transform(X_groups.fillna(0))  # ç”¨äºé€è¡Œé¢„æµ‹ T1(exp)

for i, row in df.iterrows():
    try:
        material_id = row.iloc[0]

        # â€”â€” åŸºå›¢å‘é‡ï¼ˆç¡®ä¿æ•°å€¼ï¼‰
        Nk_series = row[group_cols].astype(float)
        if pd.isna(Nk_series).any():
            continue
        Nk = Nk_series.values

        # â€”â€” é¢„æµ‹ä¾§ï¼šT1_pred, T2_pred, Cp1_pred, Cp2_pred
        T1_exp_pred = float(T1_model.predict(X_poly_all[i:i+1])[0])
        if not np.isfinite(T1_exp_pred) or T1_exp_pred <= 0:
            continue
        T1_pred = Tc0 * np.log(T1_exp_pred)
        T2_pred = 1.5 * T1_pred

        Nk_df = pd.DataFrame([Nk], columns=group_cols).fillna(0)
        Cp1_pred = float(Cp1_model.predict(Nk_df)[0])
        Cp2_pred = float(Cp2_model.predict(Nk_df)[0])
        if not (np.isfinite(Cp1_pred) and np.isfinite(Cp2_pred)):
            continue

        # â€”â€” çœŸå®ä¾§ï¼šCp1_true, Cp2_true, T1_true, T2_true
        Cp1_true = row.iloc[CP1_TRUE_IDX]
        Cp2_true = row.iloc[CP2_TRUE_IDX]
        T1_true  = row[T1_TRUE_COL]
        if not (np.isfinite(Cp1_true) and np.isfinite(Cp2_true) and np.isfinite(T1_true)):
            continue
        T2_true  = 1.5 * T1_true

        # â€”â€” è®¡ç®—å››ç§ slope
        num_den = {
            "A_çœŸå®Î”Cp_é¢„æµ‹Î”T": (Cp2_true - Cp1_true,  T2_pred - T1_pred),
            "B_é¢„æµ‹Î”Cp_çœŸå®Î”T": (Cp2_pred - Cp1_pred,  T2_true - T1_true),
            "C_é¢„æµ‹Î”Cp_é¢„æµ‹Î”T": (Cp2_pred - Cp1_pred,  T2_pred - T1_pred),
            "D_çœŸå®Î”Cp_çœŸå®Î”T": (Cp2_true - Cp1_true,  T2_true - T1_true),
        }
        slopes = {k: (np.nan if den == 0 else num/den) for k, (num, den) in num_den.items()}

        # â€”â€” é€æ¸©åº¦ç‚¹å±•å¼€
        temps = row[temp_cols].astype(float).values
        cps   = row[cp_cols].astype(float).values
        mask_pts = np.isfinite(temps) & np.isfinite(cps)
        if not mask_pts.any():
            continue

        for key in variants.keys():
            s = slopes[key]
            if not np.isfinite(s):
                continue
            for T, Cp in zip(temps[mask_pts], cps[mask_pts]):
                # ä½ çš„åŸå§‹ç‰¹å¾ï¼šNk + T + slope*T
                feats = np.concatenate([Nk, [T], [s * T]])
                datasets[key]["X"].append(feats)
                datasets[key]["y"].append(Cp)
                datasets[key]["id"].append(material_id)
                datasets[key]["T"].append(T)
    except Exception as e:
        print(f"[WARN] row {i} skipped: {e}")
        continue

# è½¬æ•°ç»„ & æ£€æŸ¥
for key in datasets:
    datasets[key]["X"] = np.asarray(datasets[key]["X"])
    datasets[key]["y"] = np.asarray(datasets[key]["y"])
    n = datasets[key]["X"].shape[0]
    print(f"ğŸ§ª {key} æ ·æœ¬æ•°: {n}")
    if n == 0:
        raise RuntimeError(f"{key} æ²¡æœ‰å¯ç”¨æ ·æœ¬ï¼Œè¯·æ£€æŸ¥åˆ—ç±»å‹ä¸ç¼ºå¤±ã€‚")

# 5. æ‹Ÿåˆæœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆéšæœºæ£®æ—ï¼‰â€”â€” å››å¥—
def eval_and_print(tag, model, X, y):
    y_pred = model.predict(X)
    mse = mean_squared_error(y, y_pred)
    r2  = r2_score(y, y_pred)
    ard = np.mean(np.abs((y - y_pred) / y)) * 100
    rel = np.abs((y - y_pred) / y) * 100
    within_1  = int((rel <= 1).sum())
    within_5  = int((rel <= 5).sum())
    within_10 = int((rel <= 10).sum())

    print(f"\nğŸ“Š æ¨¡å‹è¯„ä¼°ï¼ˆ{tag}ï¼Œå« slopeÃ—T ç‰¹å¾ï¼‰ï¼š")
    print(f"RÂ²  = {r2:.4f}")
    print(f"MSE = {mse:.2f}")
    print(f"ARD = {ard:.2f}%")
    print(f"âœ… è¯¯å·® â‰¤ 1% çš„ç‚¹æ•°: {within_1}")
    print(f"âœ… è¯¯å·® â‰¤ 5% çš„ç‚¹æ•°: {within_5}")
    print(f"âœ… è¯¯å·® â‰¤ 10% çš„ç‚¹æ•°: {within_10}")
    return y_pred

models = {}
preds  = {}

for key in variants:
    X = datasets[key]["X"]; y = datasets[key]["y"]
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X, y)
    models[key] = model
    preds[key]  = eval_and_print(key, model, X, y)

# 6. ä¿å­˜é¢„æµ‹ç»“æœï¼ˆå››ä»½ï¼‰
for key in variants:
    out = pd.DataFrame({
        "Material_ID": datasets[key]["id"],
        "Temperature (K)": datasets[key]["T"],
        "Cp_measured": datasets[key]["y"],
        "Cp_predicted": preds[key]
    })
    fname = f"Cpé¢„æµ‹ç»“æœ_RF_{key}.xlsx"
    out.to_excel(fname, index=False)
    print(f"âœ… å·²ä¿å­˜é¢„æµ‹ç»“æœä¸º: {fname}")
