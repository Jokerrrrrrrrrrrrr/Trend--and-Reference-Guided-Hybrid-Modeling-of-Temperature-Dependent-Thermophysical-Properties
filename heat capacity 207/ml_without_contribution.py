import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.linear_model import HuberRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

# 1. è¯»å–æ•°æ®
file_path = "heat capacity 207.xlsx"
df = pd.read_excel(file_path, sheet_name="Sheet1")
df = df.dropna(subset=[df.columns[0]])
df[df.columns[0]] = df[df.columns[0]].astype(int)

# 2. åˆ—å®šä¹‰
group_cols = df.columns[11:30]  # 12ä¸ªåŸºå›¢åˆ—
temp_cols = df.columns[30:40]  # 10ä¸ªæ¸©åº¦ç‚¹
cp_cols = df.columns[40:50]
target_column_T1 = 'ASPEN Half Critical T'
Tc0 = 138

# 3. å­æ¨¡å‹è®­ç»ƒï¼šç”¨äºä¼°ç®— T1, Cp1, Cp2 â†’ è®¡ç®— slope
X_groups = df[group_cols]
valid_mask = ~df[target_column_T1].isna()
poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly.fit_transform(X_groups[valid_mask])
y_exp_T1 = np.exp(df.loc[valid_mask, target_column_T1] / Tc0)

T1_model = HuberRegressor(max_iter=9000).fit(X_poly, y_exp_T1)
Cp1_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 9])
Cp2_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 50])

# 4. æ„å»ºè®­ç»ƒæ•°æ®
X_total, y_total, material_ids, temperatures = [], [], [], []
X_poly_all = poly.transform(X_groups)

for i, row in df.iterrows():
    material_id = row.iloc[0]
    Nk = row[group_cols].values
    temps = row[temp_cols].values
    cps = row[cp_cols].values

    Nk_df = pd.DataFrame([Nk], columns=group_cols)
    Nk_poly = X_poly_all[i:i + 1]

    try:
        T1_exp = T1_model.predict(Nk_poly)[0]
        if T1_exp <= 0 or np.isnan(T1_exp):
            continue
        T1 = Tc0 * np.log(T1_exp)
        T2 = T1 * 1.5
        Cp1 = Cp1_model.predict(Nk_df)[0]
        Cp2 = Cp2_model.predict(Nk_df)[0]
        slope = (Cp2 - Cp1) / (T2 - T1)
    except:
        continue

    # è®¡ç®—é¢„æµ‹çš„æ–œç‡ï¼ˆæ¯ä¸¤ä¸ªç›¸é‚»ç‚¹çš„æ–œç‡ï¼‰
    predicted_slopes = []
    for j in range(1, len(temps)):
        delta_Cp = cps[j] - cps[j - 1]  # é¢„æµ‹çƒ­å®¹å˜åŒ–
        delta_T = temps[j] - temps[j - 1]  # æ¸©åº¦å˜åŒ–
        predicted_slopes.append(delta_Cp / delta_T)  # è®¡ç®—æ–œç‡

    predicted_slopes = np.array(predicted_slopes)

    # è®¡ç®—ä¸ç›®æ ‡æ–œç‡çš„å·®å¼‚ï¼ˆç›®æ ‡æ–œç‡æ˜¯ç”±å­æ¨¡å‹ç»„åˆå¾—åˆ°çš„ï¼‰
    slope_diff = np.abs(predicted_slopes - slope)

    # æ–œç‡æƒ©ç½šï¼šè¶…å‡ºèŒƒå›´æ—¶æ–½åŠ æƒ©ç½šï¼ˆä¾‹å¦‚ 10% è¯¯å·®èŒƒå›´ï¼‰
    delta_slope = 0.10  # è®¾å®šæ–œç‡å…è®¸çš„è¯¯å·®èŒƒå›´
    penalty_factor = 100  # æƒ©ç½šåŠ›åº¦
    penalty = np.where(slope_diff > delta_slope * slope, penalty_factor * (slope_diff - delta_slope * slope), 0)

    for T, Cp in zip(temps, cps):
        if np.isnan(T) or np.isnan(Cp):
            continue

        features = np.concatenate([
            Nk,  # 12 ä¸ªåŸºå›¢
            [T],  # æ¸©åº¦
            [slope]  # å®é™…æ–œç‡ï¼ˆslopeï¼‰
        ])
        X_total.append(features)
        y_total.append(Cp)
        material_ids.append(material_id)
        temperatures.append(T)


# 5. å®šä¹‰è‡ªå®šä¹‰æŸå¤±å‡½æ•°ï¼ˆæƒ©ç½šæ–œç‡è¯¯å·®ï¼‰
def custom_objective(y_true, y_pred):
    """
    è‡ªå®šä¹‰æŸå¤±å‡½æ•°ï¼šè®¡ç®—æ–œç‡è¯¯å·®å¹¶åŠ å…¥æƒ©ç½šã€‚
    """
    # è®¡ç®—ä¸€é˜¶å¯¼æ•°ï¼ˆæ¢¯åº¦ï¼‰å’ŒäºŒé˜¶å¯¼æ•°ï¼ˆæµ·æ£®çŸ©é˜µï¼‰
    slope_pred = np.diff(y_pred) / np.diff(temperatures)  # è®¡ç®—é¢„æµ‹æ–œç‡
    slope_target = slope * np.ones_like(slope_pred)  # å‡è®¾ç›®æ ‡æ–œç‡ä¸ºå·²è®¡ç®—çš„å¸¸é‡
    slope_diff = np.abs(slope_pred - slope_target)

    # æ–œç‡è¯¯å·®æƒ©ç½š
    delta_slope = 0.10  # å®¹å¿èŒƒå›´
    penalty_factor = 100  # æƒ©ç½šåŠ›åº¦
    penalty = np.where(slope_diff > delta_slope * slope_target,
                       penalty_factor * (slope_diff - delta_slope * slope_target), 0)

    # è®¡ç®—æ ‡å‡†çš„å‡æ–¹è¯¯å·®
    mse_loss = np.mean((y_true - y_pred) ** 2)

    # æ€»æŸå¤± = MSE + æ–œç‡æƒ©ç½š
    total_loss = mse_loss + np.mean(penalty)

    # è®¡ç®—æ¢¯åº¦ï¼ˆå¯¼æ•°ï¼‰
    grad = 2 * (y_pred - y_true)  # æ¢¯åº¦æ˜¯è¯¯å·®çš„å¯¼æ•°
    hess = np.ones_like(grad)  # æµ·æ£®çŸ©é˜µæ˜¯æ¢¯åº¦çš„äºŒé˜¶å¯¼æ•°

    return grad, hess


# 6. æ‹Ÿåˆ XGBoost æ¨¡å‹ï¼ˆä½¿ç”¨è‡ªå®šä¹‰æŸå¤±å‡½æ•°ï¼‰
model = xgb.XGBRegressor(n_estimators=100, random_state=42)
model.fit(X_total, y_total)

# 7. è¯„ä¼°æ¨¡å‹
y_pred = model.predict(X_total)
mse = mean_squared_error(y_total, y_pred)
r2 = r2_score(y_total, y_pred)
ard = np.mean(np.abs((y_total - y_pred) / y_total)) * 100  # <-- æ–°å¢ ARD

# === æ–°å¢è¯¯å·®èŒƒå›´ç»Ÿè®¡ ===
relative_error = np.abs((y_total - y_pred) / y_total) * 100
within_1pct = np.sum(relative_error <= 1)
within_5pct = np.sum(relative_error <= 5)
within_10pct = np.sum(relative_error <= 10)

print("\nğŸ“Š æ¨¡å‹è¯„ä¼°ï¼ˆå« slopeÃ—T ç‰¹å¾ï¼‰ï¼š")
print(f"RÂ²  = {r2:.4f}")
print(f"MSE = {mse:.2f}")
print(f"ARD = {ard:.2f}%")
print(f"âœ… è¯¯å·® â‰¤ 1% çš„ç‚¹æ•°: {within_1pct}")
print(f"âœ… è¯¯å·® â‰¤ 5% çš„ç‚¹æ•°: {within_5pct}")
print(f"âœ… è¯¯å·® â‰¤ 10% çš„ç‚¹æ•°: {within_10pct}")

# 8. ä¿å­˜é¢„æµ‹ç»“æœ
results = pd.DataFrame({
    "Material_ID": material_ids,
    "Temperature (K)": temperatures,
    "Cp_measured": y_total,
    "Cp_predicted": y_pred
})
results.to_excel("Cpé¢„æµ‹ç»“æœ_slopeTç‰¹å¾_XGBoostæ¨¡å‹.xlsx", index=False)
print("âœ… å·²ä¿å­˜é¢„æµ‹ç»“æœä¸º: Cpé¢„æµ‹ç»“æœ_slopeTç‰¹å¾_XGBoostæ¨¡å‹.xlsx")
