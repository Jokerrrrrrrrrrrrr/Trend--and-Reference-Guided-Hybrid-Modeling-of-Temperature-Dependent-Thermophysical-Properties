import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import HuberRegressor
from sklearn.preprocessing import PolynomialFeatures

# ==== 1. è¯»å–æ•°æ® ====
df = pd.read_excel("heat of vaporization 204.xlsx", sheet_name="Sheet1")

# ==== 2. å®šä¹‰åˆ— ====
group_cols = df.columns[13:32]   # ç¬¬14~25åˆ—ï¼šåŸºå›¢
temp_cols = df.columns[32:42]    # ç¬¬26~35åˆ—ï¼šæ¸©åº¦
hvap_cols = df.columns[42:52]    # ç¬¬36~45åˆ—ï¼šHvap

# ==== 3. å‡†å¤‡ slope æ‰€éœ€æ¨¡å‹è¾“å…¥ ====
df_298 = pd.read_excel("selected_25_descriptors_data_298.xlsx")
X_298 = df_298.drop(columns=["Heat of vaporization at normal temperature"])
rf_298 = RandomForestRegressor(random_state=42).fit(X_298, df_298["Heat of vaporization at normal temperature"])
HVap_298_all = rf_298.predict(X_298)

df_Tb = pd.read_excel("selected_25_descriptors_data_boiling_point.xlsx")
X_Tb = df_Tb.drop(columns=["Heat of vaporization at boiling temperature"])
rf_Tb = RandomForestRegressor(random_state=42).fit(X_Tb, df_Tb["Heat of vaporization at boiling temperature"])
HVap_Tb_all = rf_Tb.predict(X_Tb)

# ==== 4. Tb æ¨¡å‹é¢„æµ‹ ====
Nk_all = df.iloc[:, 13:25].apply(pd.to_numeric, errors='coerce')
Tb_raw = df.iloc[:, 5].values
Tb0 = 222.543
poly = PolynomialFeatures(degree=2, include_bias=False)
Nk_poly = poly.fit_transform(Nk_all)

mask_tb = ~np.isnan(Tb_raw)
model_Tb = HuberRegressor(max_iter=5000).fit(Nk_poly[mask_tb], np.exp(Tb_raw[mask_tb] / Tb0))
Tb_pred_all = Tb0 * np.log(np.clip(model_Tb.predict(Nk_poly), 1e-6, None))

# ==== 5. è®¡ç®— slope å¹¶åŠ å…¥ä¸» DataFrame ====
T_ref = 298.15
slope_values = (HVap_Tb_all - HVap_298_all) / (Tb_pred_all - T_ref)
df["slope"] = slope_values

# ==== 6. è®¡ç®—æ®‹å·® ====
Cp1_residual = HVap_Tb_all - df_Tb["Heat of vaporization at boiling temperature"].values
Cp2_residual = HVap_298_all - df_298["Heat of vaporization at normal temperature"].values

# ==== 7. æ‰©å±• Cp1_residual å’Œ Cp2_residual ====
Cp1_residual_2d = Cp1_residual.repeat(10, axis=0).reshape(-1, 1)  # å°† Cp1_residual æ‰©å±•ä¸º 2040 è¡Œ
Cp2_residual_2d = Cp2_residual.repeat(10, axis=0).reshape(-1, 1)  # å°† Cp2_residual æ‰©å±•ä¸º 2040 è¡Œ

# ==== 8. æ„å»ºè®­ç»ƒæ•°æ® ====
X_total, y_total, material_ids, temperatures = [], [], [], []

for i, row in df.iterrows():
    material_id = row.iloc[0]
    Nk = row[group_cols].values
    temps = row[temp_cols].values
    hvaps = row[hvap_cols].values
    slope = row["slope"]

    # é‡å¤ç‰¹å¾æ„å»ºï¼Œç¡®ä¿æ‰€æœ‰æ•°æ®è¡Œæ•°ä¸€è‡´
    for T, Hv in zip(temps, hvaps):
        if np.isnan(T) or np.isnan(Hv) or np.isnan(slope):
            continue
        features = np.concatenate([Nk, [T], [slope], Cp1_residual_2d[i], Cp2_residual_2d[i]])  # åŠ å…¥æ‰©å±•çš„æ®‹å·®
        X_total.append(features)
        y_total.append(Hv)
        material_ids.append(material_id)
        temperatures.append(T)

X_total = np.array(X_total)
y_total = np.array(y_total)

# ==== 9. æ‹Ÿåˆæ¨¡å‹ ====
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_total, y_total)

# ==== 10. æ¨¡å‹è¯„ä¼° ====
y_pred = model.predict(X_total)
r2 = r2_score(y_total, y_pred)
mse = mean_squared_error(y_total, y_pred)
ard = np.mean(np.abs((y_pred - y_total) / y_total)) * 100  # ARD %

print("\nğŸ“Š æ¨¡å‹è¯„ä¼°ï¼ˆåŸºå›¢ + æ¸©åº¦ + slope ç‰¹å¾ï¼‰ï¼š")
print(f"RÂ²  = {r2:.4f}")
print(f"MSE = {mse:.2f}")
print(f"ARD = {ard:.2f}%")

# è®¡ç®—ç›¸å¯¹è¯¯å·®
relative_error = np.abs((y_pred - y_total) / y_total) * 100

# ç»Ÿè®¡ä¸åŒè¯¯å·®é˜ˆå€¼å†…çš„ç‚¹æ•°
within_1pct = np.sum(relative_error <= 1)
within_5pct = np.sum(relative_error <= 5)
within_10pct = np.sum(relative_error <= 10)

print(f"ç›¸å¯¹è¯¯å·® â‰¤ 1% çš„ç‚¹æ•°: {within_1pct}")
print(f"ç›¸å¯¹è¯¯å·® â‰¤ 5% çš„ç‚¹æ•°: {within_5pct}")
print(f"ç›¸å¯¹è¯¯å·® â‰¤ 10% çš„ç‚¹æ•°: {within_10pct}")

# ==== 11. ä¿å­˜ç»“æœ ====
results = pd.DataFrame({
    "Material_ID": material_ids,                  # åŒ–åˆç‰©ID
    "Temperature (K)": temperatures,              # æ¸©åº¦
    "Hvap_measured": y_total,                     # çœŸå®çš„è’¸å‘çƒ­
    "Hvap_predicted": y_pred,                     # é¢„æµ‹çš„è’¸å‘çƒ­
    "Absolute Error": np.abs(y_total - y_pred),   # ç»å¯¹è¯¯å·®
    "Relative Error (%)": 100 * np.abs((y_total - y_pred) / y_total),  # ç›¸å¯¹è¯¯å·®
    "Cp1_residual": Cp1_residual_2d.flatten(),    # ä½¿ç”¨è®¡ç®—å¾—åˆ°çš„ Cp1 æ®‹å·®
    "Cp2_residual": Cp2_residual_2d.flatten()     # ä½¿ç”¨è®¡ç®—å¾—åˆ°çš„ Cp2 æ®‹å·®
})

# è¾“å‡ºç»“æœå¹¶ä¿å­˜
results.to_excel("Hvap_prediction_with_slopeT_and_intercept_19group_with_residuals.xlsx", index=False)
print("âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜ä¸º Hvap_prediction_with_slopeT_and_intercept_19group_with_residuals.xlsx")
